\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {1}A Two Level $L_1$ Parameter Cascade Using the MM Alogrithm.}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}$L_1$ Estimation for the Inner Problem}{1}}
\citation{small1990survey}
\citation{small1990survey}
\citation{boyd2004convex}
\citation{hunter2004tutorial}
\citation{lange2004optimization}
\citation{lange2010numerical}
\citation{wu2010mm}
\citation{lange2007slides}
\citation{hunter2004tutorial}
\citation{lange2007slides}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}An MM Algorithm For Computing the Median}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Penalised $L_1$ Fitting}{3}}
\newlabel{sec:mm_l1_algorithm}{{1.1.2}{3}}
\citation{rudin1964principles}
\citation{mclachlan2007algorithm}
\citation{wu2010mm}
\citation{lange2010numerical}
\newlabel{eqn:wpensse}{{1.1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Discussion}{4}}
\newlabel{sec:discuss}{{1.1.3}{4}}
\@writefile{toc}{\contentsline {subsubsection}{Estimating the Worst Case Running Time}{4}}
\citation{mclachlan2007algorithm}
\citation{hunter2004tutorial}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}Testing the Algorithm on the Melanoma Data}{6}}
\newlabel{sec:testing}{{1.1.4}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Comparison of $L_1$ and $L_2$ inner fits to Cauchy perturbed data with $\omega $ fixed at 0.3\relax }}{7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:mela_l1_l2}{{1.1}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Plot of values and log differences for SAE Statistic\relax }}{8}}
\newlabel{fig:sae_plot}{{1.2}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Plot of log norm differences for coefficients. Note that they tend to settle on a line.\relax }}{9}}
\newlabel{fig:coef_plot}{{1.3}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Plot of PENSAE statistic as the algorithm proceeds.\relax }}{9}}
\newlabel{fig:pensae_plot}{{1.4}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}The Two Level Parameter Cascade with $L_1$ Norm}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Fitting an $L_1$ Parameter Cascade to the Melanoma Data\relax }}{11}}
\newlabel{fig:mela_l1_cascade}{{1.5}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces $L_1$ and $L_2$ Parameter Cascades with the same perturbed data as in Figure 1.1\hbox {}. Compare the $L_1$ curve in this plot with the one in Figure 1.5\hbox {}.\relax }}{12}}
\newlabel{fig:mela_l1_l2_cascade}{{1.6}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces All possible combinations of $L_1$ and $L_2$ loss functions that can be used for the Parameter Cascade. The top plot applies them to the orginal melanoma data, the bottom to the same perturbed data as in Figures 1.1\hbox {} and 1.6\hbox {}\relax }}{13}}
\newlabel{fig:mela_l1_l2_combiations}{{1.7}{13}}
\citation{mclachlan2007algorithm}
\citation{wu2010mm}
\citation{dempster1977maximum}
\citation{mclachlan2007algorithm}
\citation{isaacson2012analysis}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Acclerating The Rate of Convergence}{14}}
\citation{mclachlan2007algorithm}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Illustrative Example: Using Imputation to Fit an ANOVA Model With Missing Data}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Generalisations}{15}}
\newlabel{eqn:rec_seq}{{1.3}{15}}
\newlabel{eqn:rec_trans}{{1.4}{15}}
\citation{isaacson2012analysis}
\citation{chan2017acceleration}
\citation{dempster1977maximum}
\@writefile{toc}{\contentsline {paragraph}{Other Approaches:}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Log Errors for original sequnce of SSE values and the accelerated one\relax }}{17}}
\newlabel{fig:sse_error}{{1.8}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces More sophisticated acceleration methods can provide a further boost to convergence. There are gaps in the plot because the more accelerated iterations have no valid log error since R cannot numerically distinguish them from the final limit.\relax }}{17}}
\newlabel{fig:double_sse_error}{{1.9}{17}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Iterations of the original sequence $SSE_n,$ the accelerated sequence $ASSE_n,$ the quadratically accelerated sequence $QASSE_n,$ and the doubly accelerated sequence $DASSE_n.$\relax }}{18}}
\newlabel{tab:sse_error}{{1.1}{18}}
\citation{graves2000epsilon}
\citation{osada1993acceleration}
\citation{wimp1981sequence}
\citation{osada1993acceleration}
\citation{osada1993acceleration}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Accelerating the SAE sequence generating by the $L_1$ fitting alogrithm using Aitken's Method. The improvement in covergence is mediocre.\relax }}{19}}
\newlabel{fig:sae_accel}{{1.10}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Accelerating the $L_1$ Fitting Alogrithm}{19}}
\citation{*}
\bibstyle{plain}
\bibdata{ref}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces Accelerating the SAE sequence using multiple methods. Aitken's method performs the best, despite it's lack of sophistication.\relax }}{20}}
\newlabel{fig:sae_multi_accel}{{1.11}{20}}
\bibcite{boyd2004convex}{1}
\bibcite{brent2013algorithms}{2}
\bibcite{cao2007parameter}{3}
\bibcite{chan2017acceleration}{4}
\bibcite{chong2013introduction}{5}
\bibcite{dempster1977maximum}{6}
\bibcite{fornberg1988generation}{7}
\bibcite{graves2000epsilon}{8}
\bibcite{hunter2004tutorial}{9}
\bibcite{isaacson2012analysis}{10}
\bibcite{kelley2011implicit}{11}
\bibcite{kelly2002filtering}{12}
\bibcite{kiefer1953sequential}{13}
\bibcite{lange2004optimization}{14}
\bibcite{lange2010numerical}{15}
\bibcite{lange2007slides}{16}
\bibcite{leveque2007finite}{17}
\bibcite{mcconnell2004code}{18}
\bibcite{mclachlan2007algorithm}{19}
\bibcite{nocedalnumerical}{20}
\bibcite{osada1993acceleration}{21}
\bibcite{pawitan2001all}{22}
\bibcite{rlanguage}{23}
\bibcite{rudin1964principles}{24}
\bibcite{small1990survey}{25}
\bibcite{desolve}{26}
\bibcite{vandebogart2017method}{27}
\bibcite{wimp1981sequence}{28}
\bibcite{mathematicsdata2018}{29}
\bibcite{wu2010mm}{30}
